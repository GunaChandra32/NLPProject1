Bi-Gram:
A bi-gram model is a statistical language model that analyzes the frequency of adjacent pairs of words in a text. The model estimates the likelihood of a given sequence of words by using this information. Bi-gram models are commonly used in natural language processing for tasks such as speech recognition and text classification.

Tri-Gram:
On the other hand, tri-gram models consider triplets of words in a text document. By analyzing sequences of three words at a time, tri-gram models capture even more information about the context of words and can provide more accurate predictions. However, tri-gram models can be computationally expensive and require more training data than uni-gram or bi-gram models.

4-Gram:
In a 4-gram model, each word in a sentence is predicted based on the four previous words. This model can provide even more accurate predictions than bi-gram or tri-gram models. However, the 4-gram model has a high computational cost and requires a large amount of memory to store the frequency counts for all 4-grams in the corpus. Therefore, the 4-gram model is often used in applications where accuracy is critical, such as language translation and speech recognition.
